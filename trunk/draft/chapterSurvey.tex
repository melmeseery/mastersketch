\chapter{Literature Survey}
\label{sec:survey}
% this will contians only the finished work .... and my comments to view the old survey see the file
%draft_chaptersurvey 
%\section{Introduction }
%\label{sec:Introduction}
The history of pen and sketch based computing goes back to 1963 with Ivan Sutherland's SKETCHPAD \cite{sutherlandsketch}, which used a light pen to draw on the monitor to create circuit diagrams. Current technology and the increase in computing power have increased the abilities of such interfaces and allowed the implementation of fully sketching systems. Over the years, many other sketching based systems have been developed. Through this history most system focused on building the interactive interfaces to assist users while entering information to the computer. To demonstrate our system inspiration we will first present current research in the area of sketch recognition. In Section \ref{sec:preprocessing}, preprocessing and segmentation methods will be discussed in details. Later, symbol recognition methods will be presented and analyzed in Section \ref{sec:symbolrecogntion}. 


% i need to write a history then small introduction to the survey...
%  i have to state that the next  sections will generally group segmentation and symbol recognition task. 
\section{Preprocessing and Segmentation}
\label{sec:preprocessing}
  In a system that supports free hand sketching, sketching should be as natural as possible. This means that the user can draw symbols using single or multiple strokes without constrains. The goal of a sketch system is making the user feel that using the system is nearly the same as using a pencil and paper. But sketches are incomplete drawings that are sloppy and messy, for example figures \ref{fig:Overshootandundershoot} and \ref{fig:overstroked} show examples of messy sketches drawn by users. This led researchers to perform sort of preprocessing before starting the sketch recognition task itself. The next sections explain different preprocessing techniques. 
   
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/Overshootandundershoot.eps}
	\caption[Neat and Sloppy Symbols] {A sloppy and neat versions of symbol \cite{threeproblmes23}.}
	\label{fig:Overshootandundershoot}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/overstroked.eps}
	\caption[Example of an over traced stroke]{Example of an over traced stroke \cite{overtraced24}}
	\label{fig:overstroked}
\end{figure} 

 %The preprocessing can be noise removing, stroke beautification or segmentation.  %Because of this 
 Sezgin and Davis \cite{overtraced24} tried to solve the over traced strokes (see Figure \ref {fig:overstroked})using a thinning algorithm. In \cite{meanshift10,domainindependent17}, Yu uses mean shift procedure as a noise remover and preprocessing step to the recognition step. The mean shift procedure is simply shifting the point to the average of its neighborhoods so smoothing out the noise without changing the global structure of data. Gaussian filters was used to smooth curves \cite {Phoenix88}. These procedures may seem to remove noises in the sketch but it often treat vertices as noise which obscure vertex locations. \\
 %% now the third paragraph..... 
Beside points location information (x, y positions) researcher made uses of the extra information from using digital ink. Some as \cite{mulitstroke5,polygonfeedback31} used stroke speed information to detect critical points where it is stated that user slow down at those critical points. Other used curvature and directions data. %Others \cite {MilitaryCOA37,computationalmodel16,polygonfeedback31}, debated on the importance of the extra information and weather the temporal and speed information is significant. 

 Agar et al. \cite{polygonfeedback31} used the timestamp for each point and compute time difference between every two successive point to help him find corners as he argued that it provides more distinct maximum than the speed information. He mentions that the pointing device (for example the mouse) sampling rate is the reason for this phenomena. The points are sampled at regular time intervals while the pointing device is moving. There are no points while the pointing device is stationary. This leads to a nearly constant time difference between samples while the pen is moving and large difference while the pen is stationary. Contrary to speed information, where the user draws with variant speeds which tends to make the speed information include a lot of noise in the data.
  
Sezgin et al.\cite{earlyprocess} used both speed and direction information. Their system gives better results than using only speed or direction information. This is because the speed information tend to be noisy when drawing large symbols, on the other side when using only direction information the some corner are missed. Our system uses speed, direction and time difference information in its preliminary calculation step. This ensures that all the possible vertices are considered when the segmentation algorithm segments strokes. %both speed and direction information help detecting vertices when the 
 


  % third should speech on how systems define critical points (this paragrah should speak on the data collected (speed crital points, ... 

 After critical point detection most sketch system proceeds to label segments into simple geometric primitives (i.e line, arc, etc...).  A hybrid algorithm was introduced in \cite{earlyprocess} where different sets of segments are generated based on both curvature and speed dominant points, followed by choosing a segmentation with the least error from a generated hybrid set. However, this system is limited to recognizing only specific simple geometric shapes with a set of low level recognizers. Each low level recognizer is designed to recognize only one geometric shape using spatial and geometric information extracted from input stroke.  
 
  A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al. \cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system. Also, they did not take advantage of the curvature or local geometric properties of the digital curve. Yin \cite{PolygonApproximationPSO} used PSO to convert digital curves into polygons, our system adopts  Yin \cite{PolygonApproximationPSO} method and tries to improve it by adding curvature and other local information while segmenting strokes to achieve better segmentations. %The next section presents the general particle swarm algorithm which is used in both our segmentation algorithms. % are presented in section \ref{subsubsec:Discreteparticleswarmalgorithm}
 
 
Yu \cite{meanshift10} introduced a \textit{feature area} for each primitive and then computed the segmentation error for different types of primitives based on the computed \textit{feature area}. Figure \ref{fig:featurearearc} shows the feature area of a line and circle in Yu system, the shaded area is the difference between the computed feature area and the assumption area. His system achieved good accuracy in simple shapes (square, ellipse,...etc) but did not perform well in complex shapes. 
 
 Paulson and Hammond \cite{Paleosketch08} introduced a set of low level recognizers that were reported to achieve 98\% accuracy. However, their system similar to all low level recognizers in the way that it identifies a small set of simple shapes.% A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al.\cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system and did not take advantage of the curvature or local geometric properties of the digital curve.
 
Arvo \cite{Fluid25} Tried to combine fast morphing and basic recognition for the sketch drawn as the user draw it. It tries to move the points of strokes drawn by the user draw into one of the known shapes (ex: box, lines and circle). It uses a relaxation and least square method for circles and uses the string of forces for finding best-fit box. However, their system can only identify circle and rectangles drawn using a single stroke.  
\begin{figure}
	\centering
	\subfigure[Feature area of line an arc]{
		\includegraphics{images/featurearearc.eps}}
		\subfigure[Feature area of line]{
				\includegraphics{images/featureareline.eps}}
	\caption[Feature Area]{Feature Area \cite{meanshift10}}
	\label{fig:featurearearc}
\end{figure}

\section{Symbol Recognition}
\label{sec:symbolrecogntion}

%In this section, we review three different types of symbol recognition methods.
 Oltmans\cite{Oltmans07} mentions that symbol recognition can be based on: strokes, global shape properties, and appearance or image based\cite{Oltmans07}. The role of which each stroke plays in the structure of the sketched symbol is used to determine shapes in stroke based methods.  Image or appearance based methods focuses focus on the overall appearance of shapes rather than individual strokes. Unlike global shape properties approach, systems investigate general shape properties. Using shape properties loosens the assumption and role of each stroke in the symbol but it does not truly represent the symbol visually. 
 
 We choose to use the method based on shape property but added some geometrical and structure properties used in most stroke based approaches. Our method tries to avoid many of the problems faced by approaches based on individual strokes or global shape properties while trying to gain the additional information that the stroke based system use. In the next sections, we look into three different symbol recognition approaches, describe their advantages and challenges.  
 
 
\subsection{Stroke Based Recognition}
\label{sec:StrokebasedRecognition}
Stroke based approach is based on the assumption that each stroke has a specific role in representing the symbol. Stroke based methods examine each stroke as the user draw it to determine its role in the symbol. These methods are suited to interactive interfaces since users expected that system displays interpretation of the symbol after the stroke is drawn or after drawing a group of strokes. The majority of the research in sketch recognition has focused on stroke-based methods because of the corresponding emphasis on interactive interfaces. Most stroke based systems either represent symbols as gestures or hierarchical shape. 

\subsubsection{Gesture Recognition}
\label{sec:GuestureRecognition}

Single stroke gestures recognition was the focus of the early work in symbol recognition \cite{gestureexample12,aideddesgin22,sketchinginterfaces2}.  Gestures are pen strokes drawn by the user that can immediately recognized by the system. The result was either creating an action (e.g. deleting a shape) or drawing a shape on the screen. These systems are based on how the user draw the shape rather than how it looks. 

One of the first systems in gestures recognition is Rubine's algorithm \cite{gestureexample12} . He used Gaussian statistical classifier to classify gestures.  Simple features as length of stroke, smoothness of stroke, the angle that the first part of the gesture is drawn at and properties of the bounding box of the stroke are used to train the classifier to recognize symbols. In our system, we combine Rubine features with others to include the information on how the user draws sketch while recognizing the symbols. %In \cite{Long00}, Long shows how similarities between gestures can be analyzed.  He used this information to identify gestures that are likely to confuse the recognition system. This helped interface designers to choose gestures that are easily recognized. 

The main problem with gesture based recognition systems that they impose several constrains on how the user can draw. Gestures must be drawn using a specific order and direction to be recognized correctly. Moreover, in most cases gestures do not necessarily look like the symbols they represent (e.g. to represent a rectangle the user draws only the left edge of it). Because of these restrictions, gestures recognition systems are not suitable for free hand drawn sketches. 

\subsubsection{Hierarchical Shape Descriptions}

A Hierarchical shape descriptions was widely used in sketch systems \cite{sketchunderstanding1,HierarchicalParsing7,Ladder30,AlvaradoFreedom42,napkinGross}. Symbols are represented using hierarchical levels. The lower levels represent simple geometric primitives such as lines, arc and ellipses. Intermediate levels shapes are composed of lower level parts and constrain or connections between them. For example, a triangle is described as three lines connected at their endpoints. Higher level shapes are constructed from intermediate and lower level shapes, for example, a diode is described as a line on the top of a triangle head (acute angle).

 Systems that employ such representation must first pre-process strokes to break them into geometric primitives ( section \ref{sec:preprocessing} reviews on preprocessing methods). Recognition can then be treated as sub graph matching problem or constrain satisfaction problem.   
 
%Although not based on a formal structural model of shapes, another probabilistic approach by Szummer and Qi in [37] uses conditional random fields (CRFs) to propagate information about the labeling of one stroke fragment to its neighbors. This allows their system to assign labels to stroke fragments that cannot easily be identified in isolation and to regroup over-segmented fragments. This helps mitigate the difficulty of determining the exact granularity at which to perform fragmentation by using the context of surrounding fragments and a global interpretation of the sketch. They have applied their algorithm to the binary labeling problem of distinguishing boxes from connectors in organizational charts with good results, even in several highly ambiguous cases.
\paragraph{Sub-graph matching:}
\label{sec:GraphSearching}

Representing the symbol that the user draws as a graph transforms the classification problem into a graph-matching problem. In general, each user geometrical primitive is represented as a node of the graph and the relations between those nodes are represented as arc. Figure \ref{fig:squarescematic} shows a graph that is constructed by \cite{mulitstroke5} for a rectangle. To classify the symbols the graph constructed must be matched with the graphs in the database. 

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/squarescematic.eps}
	\caption[Semantic Graph of a Square ]{Semantic Graph of a Square \cite{mulitstroke5}}
	\label{fig:squarescematic}
\end{figure}


In the worst case, sub-graph matching is an exponential problem and thus is expensive to compute. Researcher tried to reduce complexity by restricting the search to fragments that are spatially or temporally grouped, or by using other assumptions. Some of the common assumptions are that each stroke is only part of one symbol and that user must draw one shape before drawing the next\cite{physicalmeaning6}. These assumptions add constrains on how user can draw sketches and thus violates freely drawn sketches.  Moreover, the matching process in highly affected by segmentation results. Over or under fragmentation of stroke into geometric primitive complicates the matching process.  If a stroke is broken into too many fragments then there will be extra components that will not map to any part of the symbol. If the stroke is divided enough then there will be component of the shape that are not filled while matching. The different ways of segmenting the sketches worsen the already high cost graph matching. 

 To solve this problem, \cite{mulitstroke5} provided two methods to match graphs, a simpler one using restrictive assumptions and if it fails the system uses a longer more computationally expensive search.  . Figure \ref{fig:squarescematic} shows a semantic graph that is constructed by the trainable recognizer in   \cite{mulitstroke5} for a rectangle. The trainable recognizer construct the semantic network at train time with then match the symbol user draw with the networks in the database. To match the networks quickly the system assumes the user draws the symbol with the same order as in training set. A deep heuristic graph search will employed only if no match was found. % there was no match found.



 Several other systems tried to model the matching process as a probabilistic problem \cite{HMM53,SketchRead2007}. These systems allow matching of partially satisfied shapes to propagate down to re interpret low level fragmentation hypothesis. In SKETCREAD \cite{SketchRead2007}, a dynamically generated Bayesian network represents the shape fragments hypotheses. Higher level structure of shape fragments can cause re interpretation of the geometric primitives. For example, if one head of an arrow is initially labeled as an arc and the system fragments the shape as an arrow then the belief that this stroke is an arc is decrease and the belief that it is a line increase. Finally, the arrow structure is completed and it is fully recognized. 
 
 \paragraph{Visual Descriptive Languages:}
 \label{sec:VisualDescribtiveLanguages}
 
 Avoiding graph matching problems, research tried to use languages that describe shapes instead of graphs. Visual descriptive languages represent the shape with a set of  tokens representing geometric primitives or spatial relations between smaller geometric primitives. Figures \ref{fig:arrow1} and \ref{fig:arr2} show a regular arrow with 2 shafts and head and its definition in Ladder language \cite{Ladder30}. Shape recognition is then a question of parsing the sketch document into a recognizer that parse strokes according to the constructed grammar. 
 
 Several visual grammar were introduced \cite{statisticalparsing26,Ladder30,GenericHMM28}. \cite{Ladder30,GenericHMM28}  Used visual description language which will generate the information of the structure and constrain of each object classified. The system automatically generates Java code for the recognizer for each object. The generated code cycles through the strokes drawn to check if any of the recognizers generated had interpreted any symbols partially or completely.  These systems are less computational expensive than graph matching approach but they also operate based on the output of the segmentation process. Any error in the segmentation process leads to huge error while parsing the whole sketch. Moreover, symbols cannot share strokes between them which influence and restrict how the user draws symbols. 
 % complexity of the graph matching problem 
\begin{figure}
	\centering
		\subfigure[An Arrow]
			{\label{fig:arrow1}\includegraphics[scale=0.75]{../../neededfiles/Figures/arrowladderdef1.eps}}
			\hfill
		\subfigure[Arrow grammar definition]%{\cite{Ladder30}}
		 {\label{fig:arr2}\includegraphics[scale=0.88]{../../neededfiles/Figures/arrowladderdef2.eps}}
	\caption[Arrow Definition]{Arrow Definition in \cite{Ladder30}}
		\label{fig:arrowladderdef1}
\end{figure}
 
\subsection{Global Shape Properties Based Recognition}
\label{sec:GlobalFeaturesBasedRecognition}

Drawing back from properties of individual strokes several researcher tried to use shape properties on the whole shape to classify shapes. They used global features that try to define the entire shape properties. 

 Several systems \cite{DiagramOfflineConvexHull,MulitStrokeConvexHull} presented features like ratio of bounding box to convex hull area and the ratio of the perimeter to the area.  These global features can be used to distinguish between classes. For example, a rectangle can be distinguished from a triangle by looking to the ratio of area of bounding box to the area of the convex hull. The triangle ratio will be much lower than that of the rectangle. 
 
 Fonseca et al.\cite{Cali63} created a system using similar set of features, their features were used by a number of fuzzy logic rules to identify symbols. They also used Naïve Bayes model that was trained to classify shapes based on those features. 
 
%Zernike moments were used by Hse et al. in \cite{ToADD}. 
Hse et al. \cite{HeloiseBeautification,zernike61} proposed using the magnitudes of Zernike moments as a shape property. Zernike moments are orthogonal moments which define the distribution of point in the input space. The higher the order of the moment the finer the detail level the point distribution represents. Hse et al. \cite{HeloiseBeautification,zernike61} used a SVM classifier to train the features vector calculated from the moments. Early evaluation of Zernike moments showed that they are invariant to both reflection and rotation of the input shape \cite{ZerMomentOrthogonal}. In our system we used Zernike moments as part of our feature vector. A detailed comparison between Zernike moments and other features are demonstrated in Section \ref{sec:featuresComparisions}. 
 
 
 \begin{figure}[]
	\centering
		\subfigure{Ac Source}{	

		\includegraphics[scale=0.6]{images/acSource.eps}		\label{fig:acSource}}
 
 		\subfigure{Current Source}{	
 		        
		\includegraphics[scale=0.6]{images/CurrentSource.eps} \label{fig:CurrentSource}}
	\caption{Example of Current and AC Sources}
	\label{fig:ACandCurrentSources}
\end{figure}

 
 Systems based on Global shape properties distinguish shapes by learning the different properties each shape class tends to have. These properties do not depend on the order or number of strokes and thus are only based on appearance of the shape not how the user draws it. However, individual details of the shape are impossible to distinguish using these properties. For example, it is impossible to use to differentiate between a current source symbol (circle containing and arrow Figure \ref{fig:CurrentSource}) and a Ac Source (circle containing a wave Figure \ref{fig:acSource}).  Finer details of the symbols are not represented in this approach, thus shapes that have small's details or only significant conceptual variation are not distinguished using this method. These symbols require a system to represent different levels of shape details.  
  
\subsection{Appearance Based Recognition}
\label{sec:ApperanceBasedRecognition}

In the third approach, the recognition focuses on appearance of shapes contrary to individual strokes or global shape properties. Kara \cite{imagetrainable48} used this approach while presenting a system that matches the input shape into a one of the prototypes in the database. Figure \ref{fig:template} shows an example of prototypes of some of the shapes in the system. Input shapes are first pose and scale normalized then four image similarity measures are used to match input shapes to the database prototypes. He used two measures (Hausdor distance) to measure similarity and two coefficients (Yule, Tanimoto) to measure dissimilarity. His approach allows the system to recognize a shape using only a single training sample as it is based on the shape prototype. However, the shape prototype must represent all transformation and variation the input shape can have. Moreover, they restrict the image representation to 48x48 pixels due to computational reasons. This restriction leads to eliminating some of the fine details that may be needed to distinguish some shape classes. There results on isolated symbols seem promising but the system has not been tested on full sketch that tends to have high overlapping between symbols. 
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{images/template.eps}
	\caption[Prototypes of Shapes]{Prototypes of Shapes \cite{imagetrainable48}}
	\label{fig:template}
\end{figure}

\subsection{Discussion}
\label{sec:discuss}

In all of these system only \cite{SketchRead2007} using stroke based recognition have been implemented to the fully create a system that free draw sketch and understand them. This is because the emphasis on the interactive side of the sketch system which result in large difficulties in processing free hand sketches. Methods based on gesture and global stroke properties produce systems that are dependent on assumptions about how strokes can be grouped. These systems assume that users will finish drawing a shape before moving to the next one \cite{multistrokeEvaluation,Cali63,geometrydomain49}. This let them to temporally group strokes and then recognizes them based on their strokes or global shape properties. \cite{AlvaradoDigital} argued that this assumption does not hold in natural sketches. 

Recognition based on strokes using hierarchical shape description is applied in \cite{SketchRead2007}. The principle problem in these systems is the computational complexity of the matching between shape description and geometric primitives produced in the segmentation process. Natural sketch are difficult to segment and group to create reliable fragment of geometric primitives. This is partially due to the increase of noise and other phenomena such as overlapped, over traced strokes and sharing of strokes between different symbols. Since these systems are dependable on the segmentation results, they either perform recognition using undependable segmentation results or consider different ways to segment the input sketch. 

To avoid most problems in such system, our system uses hybrid of both global shape and hierarchical description methods. Currently, our system recognize independent symbols. Each symbol is segmented and hierarchical features are computed.  Features that are representing the global description of the shape are also generated and appended to the hierarchical features. Recognition is done using SVM Linear classifier as it proved to be one of the best learning algorithms. 
%*********************************************************************************************5&&&&&&&&&&&&&&&&&&&&
%*********************************************************************************************5&&&&&&&&&&&&&&&&&&&&
%*********************************************************************************************5&&&&&&&&&&&&&&&&&&&&
%*********************************************************************************************5&&&&&&&&&&&&&&&&&&&&
%*********************************************************************************************5&&&&&&&&&&&&&&&&&&&&
\chapter{Particle Swarm Optimization}
\label{sec:ParticleSwramOptimization}

\section{Swarm Intelligence Review}
\label{sec:ParticleSwramOptimizationReview}

 Modeling how a biological swarm has been recently studied by biologist and computer scientists. Scientists in the field of artificial life try to understand how such "social animals" interact, achieve goals and evolve. Moreover, a swarm behavior that achieves some kind of swarm intelligence is increasingly interesting for engineers as they can apply it in optimization. Looking from a higher view, agents in a swarm are cooperating to achieve some purposeful behavior and achieve some common goal. A good example of this cooperation is ant groups looking for food source. A large group of simple independent agents seems to generate this behavior in what is called 'collective intelligence'. Each agent has a set of simple rules to follow, and according to the interaction of the entire group the objective is met\cite{swarmGeneral}. %with other neighborhood agents. 

Reynolds \cite{swarmflock} created 'boid' which simulated the motion of a flock of birds. Each boid is a simple agent that navigates according to his perception and a set of basic rules.  Kube and Zhange \cite{antsimulation} introduced a simulation model for ant's behavior and used in cooperative transportation. Ants leaves a trail of its movement, so when an ant find food it cannot carry alone, it can easily trace back to the colony and then a group of ants can track the trail and bring the food back. Kube and Zhange \cite{antsimulation,swarmGeneral} system seems to correctly models ants behavior with a methods of task modeling. 

The underling research in swarm intelligence led to optimization algorithm that simulates the animal social behaviors. Ant Colony Optimization (ACO) algorithm simulate how ants search for optimize path for food \cite{ACOFirst}. Real ants leave evidence of their exploration while they are searching for food. This trail is used by other ants to locate shortest distance between the colony and food location. ACO use similar type of cooperation between agents to find optimal solution.  The synchronous bird flock movement was simulated in \cite{PSOFirst,PSO2}.  Kennedy and Eberhart \cite{PSOFirst,PSO2} simulated the rules of bird flock movement and introduced the Particle Swarm Optimization Algorithm (PSO).

   The next section describes in details the Particle Swarm Optimization and its advantages and disadvantages. 
% Kennedy and Eberhart \cite{PSOFirst,PSO2} introduced Particle Swarm Optimization Algorithm (PSO). The algorithm simulate the moving Kennedy and Eberhart \cite{PSOFirst,PSO2} introduced particle swarm algorithm (PSO) as a general optimization algorithm.  
 \subsection*{Particle Swarm Optimization}
 In optimization problems, the algorithm attempts to find a feasible solution which satisfies all constrain of this problem. An optimal solution is the best feasible solution in the solution space. Several methods were used to solve optimization problems. Stochastic search is based on the assumption that good solution are near each other. Algorithms like simulating annealing and hill climbing used stochastic to find best solution. The problem in these methods is they may be trapped into a local best and fail to find the global best solution.
 
  Evolutionary algorithms (e.g. Genatic Algoirthms) explore solution using a population which is evaluated using fitness functions. The algorithms initially start with a randomly chosen population which is used to generate new population using various operators (e.g. cross over, mutation... ).  After each iteration, the population is evaluated using a fitness function and only the strongest are used to generate new population. The use of population helps to avoid stochastic search problem and explores the solution space to find better global optimal solutions, but unfortunately they may not always converge to a global best solution\cite{PSOpattern}. 
 
 Particle Swarm Algorithm\cite{PSOFirst}is a population based stochastic search where each solution is simulated as a  particle that flies around in a multidimensional search space. A fitness function is used to evaluate the goodness of each particle in solution space. But unlike evolutionally algorithm the new population is the PSO is influenced by the social cooperation of the particle rather than survival to the fittest. Each particle saves a history of the best location in the swarm and its own best location.  At the end each iteration, the particles moves to a new location based on the global best location and it own history of best location. This use of pervious particle locations gives PSO advantage over Evolutionary algorithms where no similar information is used. 
 
 PSO can be viewed as an algorithm between stochastic search and Evolutionary algorithms\cite{PSOpattern}. In general the PSO is a continuous optimization problem but experiments showed it performed as GA is discrete and binary optimization problems. The comparison between PSO and Genetic algorithm was performed in \cite{PSOGAComp} and proved that PSO generate faster, better solutions than GA especially in problems with high dimensionality.  
 
 A hybrid of PSO and other algorithms was investigated in various systems. Veeramachaneni \cite{kaylanGAPSO} used a hybrid of GA and PSO to breed solutions using GA then feed them to PSO. They demonstrated that using PSO-GA and PSO outperform using GA as an optimization algorithm. 
 
\subsection*{PSO Neighborhood Topology}  
In general the PSO algorithm have fully connected particle which means that every particle know the global best and local best of each other particle. Other forms of cooperation and organization were suggested in various systems.  \cite{grid} suggested using a grid like topology where particle are connected to four other particles around it. A ring and star topology were widely used in \cite{neighbourrhood}. The advantages over using different topology than the global best is that they slow down the swarm evolving (they need more time to propagate the best solution) which enable more space exploration and thus helps in eliminating the premature convergence problem. In \cite{hiericalPSO}, Janson and Middendorf proposed to use a dynamic and hierarchical neighborhood structure. They showed that using such structure helps in maintaining diversity over the solution space in a dynamic problem. % a PSO using a dynamic and hierarchical neighborhood structure to handle dynamic optimization problems. They demonstrated that such a structure is useful for maintaining some particle diversity in a dynamic environment.

 Other forms of cooperation were also investigated in \cite{facotrsSwarm} where the problem is divided among particles and each particle solves part of the problem. \cite{facotrsSwarm} discuss a different behavior that governs cooperation particles in the swarm system.  %were used There is various topologies used in connecting a swarm in PSO. The most used is the totally connected, star and ring topology. 
  
\subsection*{Drawbacks}

The main drawback of the particle swarm algorithm is the premature convergence problem. This happens when global best cannot be improved after a few swarm iterations. This is because the use of global best makes PSO converge to one place which is between local best and global best.  Another reason is because of the high amount of information between particle makes the solution less diverse which limit the explored solution space. This problem can be solved by using various methods; one of these methods is choosing another topology rather than the global best topology.  Another solution is using adaptive inertia $w$ (Section \ref{sec:ParticleSwarmAlgorithm}). Other methods of solving problem were introduced as improvement to the PSO algorithm. Another problem of PSO is that performance is dependent on the problem and the PSO parameter selected for this specific problem. This means that any change in the PSO parameter change the efficiency of PSO solution. The solution to this problem is proposed by using self adaptive parameters. 
 
 
\subsection*{Improvements to PSO}

There was various improvement used to improve the PSO algorithm. They mostly try to solve the problems premature converge problem and increase the diversity of the particle population. Early work on dynamic optimization was introduced by Eberhard and shi \cite{paramterSelection}, where they added the inertia weight version of PSO to find the optimum of 3 dimensional function which change every 100 iteration. Others used constrained PSO, where the general PSO Equation \ref{eq:Swarm} is constrained. Guaranteed Convergence PSO is introduced in \cite{GCPSO} where a system is guaranteed to converge to at least a local optimal solution. A repetition of this algorithm is used to insure finding of an optimal global solution. 

Other hybrid system that combines PSO with other techniques was introduced. Bayesian network and probability estimation were used to move particle to better solutions. Fuzzy rules were used to improve the general PSO algorithms in \cite{shapeFuzzy}.  

\subsection*{Particle Swarm Applications}
\label{sec:SwarmApp}

 Since 1995, when Kennedy and Eberhart \cite{PSOFirst,PSO2} introduced Particle Swarm Optimization Algorithm (PSO) the algorithm had been used in every discipline. The algorithm was used to train Neural network in \cite{PSOandNeuarl} and proved to perform better than GA algorithm. In Image processing discipline PSO was used an optimization algorithm in \cite{SwarmImageProcessing,Swarmimageprocessing2,Colorquantization,SwarmMedical}. PSO algorithm was used in \cite{PSOIMageClassification} to classify pixel to simplify the object segmentation process. Other system used in shape representation like \cite{shapeFuzzy}. Yin \cite{PolygonApproximationPSO} used Discrete PSO to optimally convert digital curves into polygons. 


\section{Discrete Particle Swarm Algorithm}
\label{sec:ParticleSwarmAlgorithm} 

  %It simulate the  % which has the best or  select a set of parameters that satisfy all constrains 

  
\subsection*{Discrite Particle Swarm Equations(DPSO)}
%\section{Particle Swarm Algorithm}
%\label{PSO}
%What is particle swarm algorithm and how it was used in related researches. 
The main idea of \textit{Particle Swarm Algorithm (PSO)} is to represent each solution with a $N$ dimension particle from the solution space \cite{PSOFirst}. Each particle moves with a direction and velocity $v_{ij}$ based on equations \ref{eq:Swarm} \& \ref{eq:Swarm1}.
\begin{equation}
%\[
p_{ij}=p_{ij}+v_{ij},
%\
\label{eq:Swarm1}
\end{equation}
where $p_{ij}$ represent the $jth$ dimension in the $ith$ particle and $v_{ij}$ is the velocity of the $jth$ dimension in the $ith$ particle.
 %Equation [\ref{eq:Swarm}] shows how velocity and direction of each particle are computed
 \begin{equation}
v_{ij}  = v_{ij} W  + c_1 r_1 (lbest_{ij}  - p_{ij} ) + c_2 r_2 (gbest_{ij}  - p_{ij} )
\label{eq:Swarm}
\end{equation}
 where $W$ is the inertia weight parameter which controls the tradeoff between exploration and exploitation, $lbest_{ij}$ is the local best particle, $gbest_{ij}$ is the global best particle, $r_1$ \& $r_2$ are random variables and $c_1$ \& $c_2$ are the swarm acceleration parameters.
 After each iteration the global best $g_{best}$ particle and the agent local best $l_{best}$ particle are evaluated based on the maximum fitness functions of all particles in the solution space. 
 
 The velocity is bounded to maximum of $V_{max}$ using Equation\ref{eq:vmax} to prevent exploding which leads to premature convergence. The solution is found after achieving a specific number of iteration or after an error threshold is achieved.
Equation \ref{eq:descrite} is used to change the general swarm algorithm into binary particle (\textit{Discrete Particle Swarm Algorithm DPSO}) which handles particle values of either $0$ or $1$ \cite{PSODisceret}. 
 \begin{equation}
   P(i)\Leftarrow 
\{
\begin{array}{c} 
1 \quad \quad if\quad r_{3}>p_{i}  \\

0 \quad \quad if\quad r_{3}<p_{i} 
\label{eq:descrite}
\end{array}\}
\end{equation} where $p_{ij}$ is the numerical values of the particle and $r_{3}$ is a random variable. 
  \begin{equation}
V_{ij}  = \frac{{V_{ij} }}{{2V_{\max } }} + 0.5
\label{eq:vmax}
\end{equation} where $V_{\max }$ is the velocity threshold.


%\subsection{The Algorithm}
%%\label{sec:ParticleSwarmAlgorithm} 
%\begin{verbatim}
% Initialize 
%    Generate N particles with M dimensions (P_i...P_N) 
%    Generate velocities for each particle for M dimension randomly. 
% Repeat till Maximum number of iteration OR Fitness 
%         For each particle P_i do the following 
%                Compute fitness  
%                Determine Lbest  
%                Check if need to change Gbest. 
%                Compute the Velocity for each dimension using eq. 
%                Check if maximum Velocity reach and limit it 
%                update particle values 
%          end . 
%        Improve all particle positions 
%  end 
%  
%  Final solution reaches in Gbest.       
%        
%        
%\end{verbatim}
  
  

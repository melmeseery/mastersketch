\chapter{Literature Survey}
\label{sec:survey}
% this will contians only the finished work .... and my comments to view the old survey see the file
%draft_chaptersurvey 
%\section{Introduction }
%\label{sec:Introduction}
The history of pen and sketch based computing goes back to 1963 with Ivan Sutherland's SKETCHPAD \cite{sutherlandsketch}, which used a light pen to draw on the monitor to create circuit diagrams. Rubine \cite{gestureexample12} Gesture recognition system. 
% i need to write a history then small introudction to the survey...
%  i have to state that the next  sections will generally group segmentation and symbol recognition task. 
\section{Preprocessing and Segmentation}
\label{sec:preprocessing}
%this section should describe how others did the first preprocessing of the problem. i have to summarize what i wrote before. 
 % first paragrah about how stroke is a messing thing and naturally it is ambigues. 
  In a system that supports free hand sketching, sketching should be as natural as possible. This means that the user can draw symbols using single or multiple strokes without constrains. The goal of a sketch system is making the user feel that using the using the system is nearly the same as using pencil and paper. But sketchs are incomplete drawings that are sloppy and messy, for example figures \ref{fig:Overshootandundershoot} and \ref{fig:overstroked} show examples of messy sketches drawn by users. This led researchers to perform sort of preprocessing before starting the sketch recognition task itself. The next sections explain different preprocessing techniques. 
   
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/Overshootandundershoot.eps}
	\caption[Neat and Sloppy symbols] {A sloppy and neat versions of symbol.}
	\label{fig:Overshootandundershoot}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/overstroked.eps}
	\caption{Example of an over traced stroke}
	\label{fig:overstroked}
\end{figure} 

 %The preprocessing can be noise removing, stroke beautification or segmentation.  %Because of this 
 Sezgin and Davis \cite{overtraced24} tried to solve the over traced strokes (see Figure \ref {fig:overstroked})using a thinning algorithm. In \cite{meanshift10,domainindependent17}, Bo Yu uses mean shift procedure as a noise remover and preprocessing step to the recognition step. The mean shift procedure is simply shifting the point to the average of its neighborhoods so smoothing out the noise without changing the global structure of data. Gaussian filters was used to smooth curves \cite {Phoenix88}. These procedures may seem to remove noises in the sketch but it often treat vertices as noise which obscure vertex locations. 
 %% now the third paragraph.....
Beside points location information (x, y positions) researcher made uses of the extra information from using digital ink. Some as \cite{mulitstroke5,polygonfeedback31} used user speed information to detect critical points where it is stated that user slow down at those critical points. Other used curvature and directions data. %Others \cite {MilitaryCOA37,computationalmodel16,polygonfeedback31}, debated on the importance of the extra information and weather the temporal and speed information is significant. 

 Agar et al. \cite{polygonfeedback31} used the timestamp for each point and compute time difference between every two successive point to help him finding corners as it provides more distinct maxima than the speed information. He mentions that the pointing device (for example the mouse) sampling rate is the reason for this phenomena. The points are sampled at regular time intervals while the pointing device is moving. There are no points while the pointing device is stationary. This leads to a nearly constant time difference between samples while the pen is moving and large difference while the pen is stationary. Contrary to speed information, where the users draw with variant speeds the speed information has a lot of noise in the data.
  
Sezgin et al.\cite{earlyprocess} used both speed and direction information. Their system gives better results than using only speed or direction information. This is because the speed information tend to be noisy when drawing large symbols, on the other side when using only direction information the some corner are missed. Our system uses speed, direction and time difference information in its preliminary calculation step.  %both speed and direction information help detecting vertices when the 
 
 A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al. \cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system. Also, they did not take advantage of the curvature or local geometric properties of the digital curve. Yin \cite{PolygonApproximationPSO} used PSO to convert digital curves into polygons, our system adopts  Yin \cite{PolygonApproximationPSO} method and tries to improve it by adding curvature and other local information while segmenting strokes to achieve better segmentations. %The next section presents the general particle swarm algorithm which is used in both our segmentation algorithms. % are presented in section \ref{subsubsec:Discreteparticleswarmalgorithm}

  % third should speech on how systems define critical points (this paragrah should speak on the data collected (speed crital points, ... 

 After critical point detection most sketch system proceeds to label segments into simple geometric primitives (i.e line, arc, etc...).  A hybrid algorithm was introduced in \cite{earlyprocess} where different sets of segments are generated based on both curvature and speed dominant points, followed by choosing a segmentation with the least error from a generated hybrid set. However, this system is limited to recognizing only specific simple geometric shapes with a set of low level recognizers. Each low level recognizer is designed to recognize only one geometric shape using spatial and geometric information extracted from input stroke.  
Yu \cite{meanshift10} introduced a \textit{feature area} for each primitive and then computed the segmentation error for different types of primitives based on the computed \textit{feature area}. Figure \ref{fig:featurearearc} shows the feature area of a line and circle in Yu system, the shaded area is the difference between the computed feature area and the assumption area. His system achieved good accuracy in simple shapes (square, ellipse,...etc) but did not perform well in complex shapes. 
 
 Paulson and Hammond \cite{Paleosketch08} introduced a set of low level recognizers that were reported to achieve 98\% accuracy. However, their system similar to all low level recognizers in the way that it identifies a small set of simple shapes.% A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al.\cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system and did not take advantage of the curvature or local geometric properties of the digital curve.
\cite{Fluid25} Trying to combine fast morphing and basic recognition for the sketch drawn as the user draw it. It tries to move the points of strokes drawn by the user draw into one of the known shapes (ex: box, lines and circle). It uses a relaxation and least square method for circles and uses the string of forces for finding best-fit box. However, their system can only identify circle and rectangles drawn using a single stroke.  
\begin{figure}
	\centering
	\subfigure[Feature area of line an arc]{
		\includegraphics{images/featurearearc.eps}}
		\subfigure[Feature area of line]{
				\includegraphics{images/featureareline.eps}}
	\caption{Feature area}
	\label{fig:featurearearc}
\end{figure}

\section{Symbol Recogntion}
\label{sec:symbolrecogntion}

In this section, we review three different types of symbol recognition methods. Symbol recognition can be based on: strokes, global shape properties, and appearance \cite{Oltmans07}. The role of which each stroke plays in the structure of the sketched symbol is used to determine shapes in stroke based methods. In global shape properties approach, systems investigate general shape properties and its underlying strokes. Using shape properties relaxes the assumption and role of each stroke in the symbol but it does not truly represent the appearance of the symbol. Unlike appearance based methods where individual strokes are disregarded and they focus on the overall appearance of shapes. We choose to use the appearance based method but added some geometrical and structure properties used in most stroke based approaches. Our method tries to avoid many of the problems faced by approaches based on individual strokes or global shape properties while trying to gain the additional information that the stroke based system use. In the next sections, we look into three different symbol recognition approaches, describe their advantages and challenges.  

\subsection{Stroke Based Recognition}
\label{sec:StrokebasedRecognition}
Stroke based approach is based on the assumption that each stroke has a specific role in representing the symbol. Stroke based methods examine each stroke as the user draw it to determine its role in the symbol. These methods are suited to interactive interfaces since users expected that system displays interpretation of the symbol after the stroke is drawn or after drawing a group of strokes. The majority of the research in sketch recognition has focused on stroke-based methods because of the corresponding emphasis on interactive interfaces. Most stroke based systems either represent symbols as gestures or   hierarchical shape. 

\subsubsection{Guesture Recognition}
\label{sec:GuestureRecognition}

Single stroke gestures recognition was the focus of the early work in symbol recognition \cite{gestureexample12,aideddesgin22,sketchinginterfaces2}.  Gestures are pen strokes drawn by the user that can immediately recognized by the system. The result was either creating an action (e.g. deleting a shape) or drawing a shape on the screen. These systems are based on how the user draw the shape rather than how it looks. 

One of the first systems in gestures recognition is Rubine's algorithm \cite{gestureexample12} . He used Gaussian statistical classifier to classify gestures.  Simple features as length of stroke, smoothness of stroke, the angle that the first part of the gesture is drawn at and properties of the bounding box of the stroke are used to train the classifier to recognize  symbols. In our system, we combine Rubine features with other to include the information on how the user draws sketch while recognizing the symbols. In \cite{Long00}  Long shows how similarities between gestures can be analyzed.  He used this information to identify gestures that are likely to confuse the recognition system. This helped interface designers to choose gestures that are easily recognized. 

The main problem with gesture based recognition system that they impose several constrains on how the user can draw. Gestures must be drawn using a specific order and direction to be recognized correctly. Moreover, in most cases gestures do not necessarily look like the symbols they represent (e.g. to represent a rectangle the user draws only the left edge of it). Because of these reasons, gestures recognition systems are not suitable for free hand drawn sketches. 

\subsubsection{Hierarchical Shape Descriptions}

A Hierarchical shape descriptions was widely used in sketch systems \cite{sketchunderstanding1,HierarchicalParsing7,Ladder30,AlvaradoFreedom42,napkinGross}. Symbols are represented using hierarchical levels. The lower levels represent simple geometric primitives such as lines, arc and ellipses. Intermediate levels shapes are composed of lower level parts and constrain or connections between them. For example, a triangle is described as three lines connected at their endpoints. Higher level shapes are constructed from intermediate and lower level shapes, for example, a diode is described as a line on the top of a triangle head (acute angle).

 Systems that employ such representation must first preprocess strokes to break them into geometric primitives (see section \ref{sec:preprocessing} for a review on preprocessing methods). Recognition can then be treated as sub graph matching problem or constrain satisfaction problem.   
 
%Although not based on a formal structural model of shapes, another probabilistic approach by Szummer and Qi in [37] uses conditional random fields (CRFs) to propagate information about the labeling of one stroke fragment to its neighbors. This allows their system to assign labels to stroke fragments that cannot easily be identified in isolation and to regroup over-segmented fragments. This helps mitigate the difficulty of determining the exact granularity at which to perform fragmentation by using the context of surrounding fragments and a global interpretation of the sketch. They have applied their algorithm to the binary labeling problem of distinguishing boxes from connectors in organizational charts with good results, even in several highly ambiguous cases.
\paragraph{Sub-graph matching:}
\label{sec:GraphSearching}

Representing the symbol that the user draws as a graph transforms the classification problem into a graph-matching problem. In general, each user geometrical primitive is represented as a node of the graph and the relations between those nodes are represented as arc.  Figure \ref{fig:squarescematic} shows a graph that is constructed by \cite{mulitstroke5} for a rectangle. To classify the symbols the graph constructed must be matched with the graphs in the database. 

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/squarescematic.eps}
	\caption{square scemantic graph}
	\label{fig:squarescematic}
\end{figure}


In the worst case, sub-graph matching is an exponential problem and thus is expensive to compute. Researcher tried to reduce complexity by restricting the search to fragments that are spatially or temporally grouped, or by using other assumption. Some of the common assumptions are that each stroke is only part of one symbol and that user must draw one shape before drawing the next\cite{physicalmeaning6}. These assumptions add constrains on how user can draw sketches and thus violates freely drawn sketches.  Moreover, the matching process in highly affected by segmentation results. Over or under fragmentation of stroke into geometric primitive complicates the matching process.  If a stroke is broken into too many fragments then the there will be extra component that will not map to any part of the symbol. If the stroke is divided enough then there will be component of the shape that are not filled while matching. The different ways of segmenting the sketches worsen the already high cost graph matching. 

 To solve this problem,  \cite{mulitstroke5} provided two methods to match graphs, a simpler one using restrictive assumptions and if it fails the system uses a longer more computationally expensive search.  . Figure \ref{fig:squarescematic} shows a semantic graph that is constructed by the trainable recognizer in   \cite{mulitstroke5} for a rectangle. The trainable recognizer construct the semantic network at train time with then match the symbol user draw with the networks in the database. To match the networks quickly the system assumes the user draws the symbol with the same order as in training set. A deep heuristic graph search will employed only if no match was found. % there was no match found.



 Several other systems tried to model the matching process as a probabilistic problem \cite{HMM53,SketchRead2007}. These systems allow matching of partially satisfied shapes to propagate down to re interpret low level fragmentation hypothesis. In SKETCREAD \cite{SketchRead2007}, a dynamically generated Bayesian network fragments represents the shape hypotheses. Higher level structure of shape fragments can cause re interpretation of the geometric primitives. For example, if one head of an arrow is initially labeled as an arc and the system fragments the shape as an arrow then the belief that this stroke is an arc is decrease and the belief that it is a line increase. Finally, the arrow structure is completed and it is fully recognized. 
 
\subsection{Global Shape Properties Based Recognition}
\label{sec:GlobalFeaturesBasedRecognition}

drawing back from properties of individual strokes several researcher tried to use shape properties on the whole shape to classify shapes. They used global features that tries to define the entire shape properties. 

 Several systems \cite{DiagramOfflineConvexHull,MulitStrokeConvexHull} presented features like ratio of bounding box to convex hull area and the ratio of the preimeter to the area.  These global feature can be used to distinguish between classes. For example, a rectangle can be distinguish from a triangle by looking to the raito of area of bounding box to the area of the convex hull. The triangle ratio will be much lower than that of the rectangle. 
 
 Fonseca et al.\cite{Cali63} created a system using similar set of features, their features were used by a number of fuzzy logic rules to identify symbols. They also used Naïve Bayes model that was trained to classify shapes based on those features. 
 
%Zernike moments were used by Hse et al. in \cite{}. 
Hse et al. \cite{HeloiseBeautification,zernike61} proposed using the magnitudes of Zernike moments as a shape property. Zernike moemnts are orthognals moments which define the distribution of point in the input space. The higher the order of the moment the finer the detail level the point distribution represents. Hse et al. \cite{HeloiseBeautification,zernike61} used a SVM classifier to train the features vector calculated from the moments. Early evluation of Zernike moemnts showed that they are invariant to both reflection and rotation of the input shape \cite{ }. In our system we used Zernike moemnts as part of our feature vector. A detailed comparison between Zernike moments and other features are demonstrated in Section \ref{}. 
 
 Systems based on Global shape properties distinguish shapes by learning the different properties each shape class tend to have. These properties dose not depend on the order or number of strokes and thus are only based on apperance of the shape not how the user draw it. However, individual details of the shape are impossible to distinguish using these properties. For example, it is impoissible to use  to  differentiate between a current source symbole (circle contiaing and arrow Figure \ref{}) and a clock (circle containing a square signal Figure \ref{}).  Finear details of the symbols are not represented in this approach, thus shapes that have smalls details or only significant conceptual variation are not distiguished using this method. These symbols requires a system to represent different levels of shape details.  
 
\subsection{Apperance Based Recognition}
\label{sec:ApperanceBasedRecognition}

In the third approach, the recognition foucus on appearance of shapes contrary to individual strokes or global shape properties. Kara \cite{imagetrainable48} used this approach while presenting a system that matches the input shape into a one of the  prototypes in the database. Figure \ref{fig:template} shows an example of prototypes of some of the shapes in the system. Input shapes are first pose and scale normalized then four image similarity measure are used to match input shapes to the database prototypes. He used two measures (Hausdor distance )  to measure similarity and two coeficients (Yule, Tanimoto) to measure dissimilarity. His approach allows the system to recongized a shape using only a single training sample as it is based on the shape prototype. However, the shape protoytpe must represent all  transformation and variation the input shape can have. Moreover, they restrict the image representation to 48x48 pixel due to computationa reasons. This restriction leads to elimintating some of the fine details that may be needed to distinguish some shape classes. There results on isolated symbols seems promising but the system have not beet tested on full sketch that tends to have high overlapping between symbols. 

\subsection{Discussion}
\label{sec:discuss}

In all of these system only \cite{4} using stroke based recognitiion have been implemented to the fully creat a system that free draw sketch and understand them. This is because the emphasis on the interactive side of the sketch sytem which result in large difficultes in processing free hand sketches. Methods based on gesture and global stroke properties produce systems that are dependent on assumptions about how strokes can be groubed. These systems assume that users will finish drawing a shape before moving to the next one \cite{6,11,14,15}. This let them to temporally group strokes and then recognize them based on their strokes or apperance properties. \cite{5} argued that this assumption dose not hold in natural sketchs. 

Recogntion based on strokes using hierarchical shape description is applied in \cite{}. The principle problem in these systems is the computatnal complexity of the matching between shape description and geometeric primitves produced in the segmentaiton process. Natural sketch are dificult to segment and group to create reliable fragment of geometeric primitives. This is partially due to the increase of noise and other phenomena such as overlapped, overtraced strokes and multiple shapes drawn using 


Natural sketches are dificult to reliably fragment into geometric primitives, because of the increase in noise and other phenomena such as interspersed drawing of parts from multiple shapes, multiple
shapes drawn with single strokes, and overtraced strokes. Because these systems are
dependent on the fragmentation process, they are either faced with performing recognition
with unreliable fragmentation results or must consider many possible ways to
fragment the sketch. Avoiding the fragmentation issue was one of our key motivating
factors in taking an appearance-based approach to recognition.
The appearance based methods described above have not been applied, to our
knowledge, to complete, freely drawn sketches. They have only been applied to
isolated shapes or synthetic images generated from isolated shapes. Although their
focus on the visual nature of the sketches appears promising for handling freely drawn
sketches they have not yet been evaluated on them.


 \chapter{Particle Swram Optimization}
\label{sec:ParticleSwramOptimization}

 
\section{Particle Swram Optimization Review}
\label{sec:ParticleSwramOptimizationReview}

%review on the pso alogrithm alone.................


\section{Discrete Particle Swarm Algorithm}
\label{sec:ParticleSwarmAlgorithm}
%\section{Particle Swarm Algorithm}
%\label{PSO}
%What is particle swarm algorithm and how it was used in related researches. 
The main idea of \textit{Particle Swarm Algorithm (PSO)} is to represent each agent with a particle from the solution space \cite{PSOFirst}. Each agent moves the particle with a direction and velocity $v_{ij}$ based on equations \ref{eq:Swarm} \& \ref{eq:Swarm1}.
\begin{equation}
%\[
p_{ij}=p_{ij}+v_{ij},
%\
\label{eq:Swarm1}
\end{equation}
where $p_{ij}$ represent the $jth$ particle in the $ith$ agent and $v_{ij}$ is the velocity of the $jth$ particle in the $ith$ agent.
 %Equation [\ref{eq:Swarm}] shows how velocity and direction of each particle are computed
 \begin{equation}
v_{ij}  = v_{ij}  + c_1 r_1 (lbest_{ij}  - p_{ij} ) + c_2 r_2 (gbest_{ij}  - p_{ij} )
\label{eq:Swarm}
\end{equation}
 where $lbest_{ij}$ is the local best particle, $gbest_{ij}$ is the global best particle, $r_1$ \& $r_2$ are random variables and $c_1$ \& $c_2$ are the swarm system variables.
 After each iteration the global best $g_{best}$ particle and the agent local best $l_{best}$ particle are evaluated based on the maximum fitness functions of all particles in the solution space. The solution is found after achieving a specific number of iteration or after an error threshold is achieved.
Equation \ref{eq:descrite} is used to change the general swarm algorithm into binary particle (\textit{Discrete Particle Swarm Algorithm DPSO}) which handles particle values of either $0$ or $1$ \cite{PSODisceret}. 
 \begin{equation}
   P(i)\Leftarrow 
\{
\begin{array}{c} 
1 \quad \quad if\quad r_{3}>p_{i}  \\

0 \quad \quad if\quad r_{3}<p_{i} 
\label{eq:descrite}
\end{array}\}
\end{equation}
 where $p_{ij}$ is the numerical values of the particle and $r_{3}$ is a random variable.
  
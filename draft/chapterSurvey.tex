\chapter{Literature Survey}
\label{sec:survey}
% this will contians only the finished work .... and my comments to view the old survey see the file
%draft_chaptersurvey 

%\section{Introduction }
%\label{sec:Introduction}
The history of pen and sketch based computing goes back to 1963 with Ivan Sutherland's SKETCHPAD \cite{sutherlandsketch}, which used a light pen to draw on the monitor to create circuit diagrams. Rubine \cite{gestureexample12} Gesture recognition system. 
% i need to write a history then small introudction to the survey...
%  i have to state that the next  sections will generally group segmentation and symbol recognition task. 
\section{Preprocessing and Segmentation}
\label{sec:preprocessing}
%this section should describe how others did the first preprocessing of the problem. i have to summarize what i wrote before. 
 % first paragrah about how stroke is a messing thing and naturally it is ambigues. 
  In a system that supports free hand sketching, sketching should be as natural as possible. This means that the user can draw symbols using single or multiple strokes without constrains. The goal of a sketch system is making the user feel that using the using the system is nearly the same as using pencil and paper. But sketchs are incomplete drawings that are sloppy and messy, for example figures \ref{fig:Overshootandundershoot} and \ref{fig:overstroked} show examples of messy sketches drawn by users. This led researchers to perform sort of preprocessing before starting the sketch recognition task itself. The next sections explain different preprocessing techniques. 
   
\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/Overshootandundershoot.eps}
	\caption[Neat and Sloppy symbols] {A sloppy and neat versions of symbol.}
	\label{fig:Overshootandundershoot}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/overstroked.eps}
	\caption{Example of an over traced stroke}
	\label{fig:overstroked}
\end{figure} 

 %The preprocessing can be noise removing, stroke beautification or segmentation.  %Because of this 
 Sezgin and Davis \cite{overtraced24} tried to solve the over traced strokes (see Figure \ref {fig:overstroked})using a thinning algorithm. In \cite{meanshift10,domainindependent17}, Bo Yu uses mean shift procedure as a noise remover and preprocessing step to the recognition step. The mean shift procedure is simply shifting the point to the average of its neighborhoods so smoothing out the noise without changing the global structure of data. Gaussian filters was used to smooth curves \cite {Phoenix88}. These procedures may seem to remove noises in the sketch but it often treat vertices as noise which obscure vertex locations. 
 %% now the third paragraph.....
Beside points location information (x, y positions) researcher made uses of the extra information from using digital ink. Some as \cite{mulitstroke5,polygonfeedback31} used user speed information to detect critical points where it is stated that user slow down at those critical points. Other used curvature and directions data. %Others \cite {MilitaryCOA37,computationalmodel16,polygonfeedback31}, debated on the importance of the extra information and weather the temporal and speed information is significant. 

 Agar et al. \cite{polygonfeedback31} used the timestamp for each point and compute time difference between every two successive point to help him finding corners as it provides more distinct maxima than the speed information. He mentions that the pointing device (for example the mouse) sampling rate is the reason for this phenomena. The points are sampled at regular time intervals while the pointing device is moving. There are no points while the pointing device is stationary. This leads to a nearly constant time difference between samples while the pen is moving and large difference while the pen is stationary. Contrary to speed information, where the users draw with variant speeds the speed information has a lot of noise in the data.
  
Sezgin et al.\cite{earlyprocess} used both speed and direction information. Their system gives better results than using only speed or direction information. This is because the speed information tend to be noisy when drawing large symbols, on the other side when using only direction information the some corner are missed. Our system uses speed, direction and time difference information in its preliminary calculation step.  %both speed and direction information help detecting vertices when the 
 
 A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al. \cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system. Also, they did not take advantage of the curvature or local geometric properties of the digital curve. Yin \cite{PolygonApproximationPSO} used PSO to convert digital curves into polygons, our system adopts  Yin \cite{PolygonApproximationPSO} method and tries to improve it by adding curvature and other local information while segmenting strokes to achieve better segmentations. %The next section presents the general particle swarm algorithm which is used in both our segmentation algorithms. % are presented in section \ref{subsubsec:Discreteparticleswarmalgorithm}

  % third should speech on how systems define critical points (this paragrah should speak on the data collected (speed crital points, ... 

 After critical point detection most sketch system proceeds to label segments into simple geometric primitives (i.e line, arc, etc...).  A hybrid algorithm was introduced in \cite{earlyprocess} where different sets of segments are generated based on both curvature and speed dominant points, followed by choosing a segmentation with the least error from a generated hybrid set. However, this system is limited to recognizing only specific simple geometric shapes with a set of low level recognizers. Each low level recognizer is designed to recognize only one geometric shape using spatial and geometric information extracted from input stroke.  
Yu \cite{meanshift10} introduced a \textit{feature area} for each primitive and then computed the segmentation error for different types of primitives based on the computed \textit{feature area}. Figure \ref{fig:featurearearc} shows the feature area of a line and circle in Yu system, the shaded area is the difference between the computed feature area and the assumption area. His system achieved good accuracy in simple shapes (square, ellipse,...etc) but did not perform well in complex shapes. 
 
 Paulson and Hammond \cite{Paleosketch08} introduced a set of low level recognizers that were reported to achieve 98\% accuracy. However, their system similar to all low level recognizers in the way that it identifies a small set of simple shapes.% A genetic algorithm was used by \cite{CruveDivisionSwarm} to optimally divide digital curves into lines and curves. Chen et al.\cite{CruveDivisionSwarm} uses digital curves scanned from paper as input to the system and did not take advantage of the curvature or local geometric properties of the digital curve.
\cite{Fluid25} Trying to combine fast morphing and basic recognition for the sketch drawn as the user draw it. It tries to move the points of strokes drawn by the user draw into one of the known shapes (ex: box, lines and circle). It uses a relaxation and least square method for circles and uses the string of forces for finding best-fit box. However, their system can only identify circle and rectangles drawn using a single stroke.  
\begin{figure}
	\centering
	\subfigure[Feature area of line an arc]{
		\includegraphics{images/featurearearc.eps}}
		\subfigure[Feature area of line]{
				\includegraphics{images/featureareline.eps}}
	\caption{Feature area}
	\label{fig:featurearearc}
\end{figure}

\section{Symbol Recogntion}
\label{sec:symbolrecogntion}

In this section, we review three different types of symbol recognition methods. Symbol recognition can be based on: strokes, global shape properties, and appearance \cite{Oltmans07}. The role of which each stroke plays in the structure of the sketched symbol is used to determine shapes in stroke based methods. In global shape properties approach, systems investigate general shape properties and its underlying strokes. Using shape properties relaxes the assumption and role of each stroke in the symbol but it does not truly represent the appearance of the symbol. Unlike appearance based methods where individual strokes are disregarded and they focus on the overall appearance of shapes. We choose to use the appearance based method but added some geometrical and structure properties used in most stroke based approaches. Our method tries to avoid many of the problems faced by approaches based on individual strokes or global shape properties while trying to gain the additional information that the stroke based system use. In the next sections, we look into three different symbol recognition approaches, describe their advantages and challenges.  

\subsection{Stroke Based Recognition}
\label{sec:StrokebasedRecognition}
Stroke based approach is based on the assumption that each stroke has a specific role in representing the symbol. Stroke based methods examine each stroke as the user draw it to determine its role in the symbol. These methods are suited to interactive interfaces since users expected that system displays interpretation of the symbol after the stroke is drawn or after drawing a group of strokes. The majority of the research in sketch recognition has focused on stroke-based methods because of the corresponding emphasis on interactive interfaces. Most stroke based systems either represent symbols as gestures or   hierarchical shape. 

\subsubsection{Guesture Recognition}
\label{sec:GuestureRecognition}

Single stroke gestures recognition was the focus of the early work in symbol recognition \cite{gestureexample12,aideddesgin22,sketchinginterfaces2}.  Gestures are pen strokes drawn by the user that can immediately recognized by the system. The result was either creating an action (e.g. deleting a shape) or drawing a shape on the screen. These systems are based on how the user draw the shape rather than how it looks. 

One of the first systems in gestures recognition is Rubine's algorithm \cite{gestureexample12} . He used Gaussian statistical classifier to classify gestures.  Simple features as length of stroke, smoothness of stroke, the angle that the first part of the gesture is drawn at and properties of the bounding box of the stroke are used to train the classifier to recognize  symbols. In our system, we combine Rubine features with other to include the information on how the user draws sketch while recognizing the symbols. In \cite{Long00}  Long shows how similarities between gestures can be analyzed.  He used this information to identify gestures that are likely to confuse the recognition system. This helped interface designers to choose gestures that are easily recognized. 

The main problem with gesture based recognition system that they impose several constrains on how the user can draw. Gestures must be drawn using a specific order and direction to be recognized correctly. Moreover, in most cases gestures do not necessarily look like the symbols they represent (e.g. to represent a rectangle the user draws only the left edge of it). Because of these reasons, gestures recognition systems are not suitable for free hand drawn sketches. 

\subsubsection{Hierarchical Shape Descriptions}

A Hierarchical shape descriptions was widely used in sketch systems \cite{sketchunderstanding1,HierarchicalParsing7,Ladder30,AlvaradoFreedom42,napkinGross}. Symbols are represented using hierarchical levels. The lower levels represent simple geometric primitives such as lines, arc and ellipses. Intermediate levels shapes are composed of lower level parts and constrain or connections between them. For example, a triangle is described as three lines connected at their endpoints. Higher level shapes are constructed from intermediate and lower level shapes, for example, a diode is described as a line on the top of a triangle head (acute angle).

 Systems that employ such representation must first preprocess strokes to break them into geometric primitives (see section \ref{sec:preprocessing} for a review on preprocessing methods). Recognition can then be treated as sub graph matching problem or constrain satisfaction problem.   
 
%Although not based on a formal structural model of shapes, another probabilistic approach by Szummer and Qi in [37] uses conditional random fields (CRFs) to propagate information about the labeling of one stroke fragment to its neighbors. This allows their system to assign labels to stroke fragments that cannot easily be identified in isolation and to regroup over-segmented fragments. This helps mitigate the difficulty of determining the exact granularity at which to perform fragmentation by using the context of surrounding fragments and a global interpretation of the sketch. They have applied their algorithm to the binary labeling problem of distinguishing boxes from connectors in organizational charts with good results, even in several highly ambiguous cases.
\paragraph{Sub-graph matching:}
\label{sec:GraphSearching}

Representing the symbol that the user draws as a graph transforms the classification problem into a graph-matching problem. In general, each user geometrical primitive is represented as a node of the graph and the relations between those nodes are represented as arc.  Figure \ref{fig:squarescematic} shows a graph that is constructed by \cite{mulitstroke5} for a rectangle. To classify the symbols the graph constructed must be matched with the graphs in the database. 

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/squarescematic.eps}
	\caption{square scemantic graph}
	\label{fig:squarescematic}
\end{figure}


In the worst case, sub-graph matching is an exponential problem and thus is expensive to compute. Researcher tried to reduce complexity by restricting the search to fragments that are spatially or temporally grouped, or by using other assumption. Some of the common assumptions are that each stroke is only part of one symbol and that user must draw one shape before drawing the next\cite{physicalmeaning6}. These assumptions add constrains on how user can draw sketches and thus violates freely drawn sketches.  Moreover, the matching process in highly affected by segmentation results. Over or under fragmentation of stroke into geometric primitive complicates the matching process.  If a stroke is broken into too many fragments then the there will be extra component that will not map to any part of the symbol. If the stroke is divided enough then there will be component of the shape that are not filled while matching. The different ways of segmenting the sketches worsen the already high cost graph matching. 

 To solve this problem,  \cite{mulitstroke5} provided two methods to match graphs, a simpler one using restrictive assumptions and if it fails the system uses a longer more computationally expensive search.  . Figure \ref{fig:squarescematic} shows a semantic graph that is constructed by the trainable recognizer in   \cite{mulitstroke5} for a rectangle. The trainable recognizer construct the semantic network at train time with then match the symbol user draw with the networks in the database. To match the networks quickly the system assumes the user draws the symbol with the same order as in training set. A deep heuristic graph search will employed only if no match was found. % there was no match found.



 Several other systems tried to model the matching process as a probabilistic problem \cite{HMM53,SketchRead2007}. These systems allow matching of partially satisfied shapes to propagate down to re interpret low level fragmentation hypothesis. In SKETCREAD \cite{SketchRead2007}, a dynamically generated Bayesian network fragments represents the shape hypotheses. Higher level structure of shape fragments can cause re interpretation of the geometric primitives. For example, if one head of an arrow is initially labeled as an arc and the system fragments the shape as an arrow then the belief that this stroke is an arc is decrease and the belief that it is a line increase. Finally, the arrow structure is completed and it is fully recognized. 
 
\subsection{Global Shape Properties Based Recognition}
\label{sec:GlobalFeaturesBasedRecognition}

To step back from properties of individual strokes several researcher tried to use shape properties on the whole shape to classify shapes. The properties used 

A number of approaches have stepped back from the properties of individual strokes to
classify shapes based on a set of properties calculated on the whole shape. Properties
that attempt to summarize the information in the entire shape are called global
features.
In [6] a carefully crafted set of filters based on global features, such as the ratio
of their bounding box area to convex hull area and the ratio of the perimeter to the
area, were used to progressively eliminate possible interpretations for a stroke until a
suitable interpretation was found. For example, rectangles can be distinguished from
triangles by looking at the ratio between the area of the convex hull and the area of
the rectangular bounding box. The ratio for rectangles will be near 1.0 and the ratio
for triangles will be near 0.5.
A similar set of features was used by Fonseca et. al. in [14]. In that system,
a carefully selected set of features was used by a number of rules and fuzzy logic
to perform classifcation. Their system could also be trained to learn to distinguish
between shape classes using a Naïve Bayes model based on the features.
A more general approach using Zernike moments was demonstrated by Hse et. al.
in [21]. Instead of using a hand tuned collection of properties they make use of the
magnitudes of Zernike moments. Zernike moments are a class of orthogonal moments
which describe the distribution of points in the input shape. Higher order moments
represent finer levels of detail in the point distribution. The magnitudes of these
moments, calculated up to a given order, form a feature vector which can be used to
train an SVM. The magnitudes of Zernike moments have been shown to be invariant
to both rotation and reflection of the input shape. A comparison of Zernike moments
to our match vector representation is presented in detail in Section 5.2.2.
These types of systems are based on global properties of shapes. Shape classes are
identified by determining which properties each class tends to have. The properties do
not typically depend on the number or order of the strokes and are thus based on the
appearance of the shape and not how it was drawn. However, they do not represent
the individual details of the shape. For example, it would be impossible to distinguish
between the symbol for a current source (circle containing an arrow) and an ac-source
(circle containing a "tilde") using just the ratio of convex hull area to bounding box
area. This approach cannot distinguishing between shapes that difier by small details,
and cannot deal with shapes that allow substantial conceptual variation. Handling
these requires an approach that can represent the shapes at multiple levels of detail

The application of Statistical classifiers in recognizing shapes are widely used in sketch recognition. Statistical classifier requires training time before the recognition actually happen. Then first step of classification is features computation that is done in the previous step. Finally, the recognition of symbols will be based on the classifier and the training set used.  

One of the first systems in sketch recognition is \citep{gestureexample12,aideddesgin22} algorithm to recognize ink gestures. He used Gaussian statistical classifier to classify any stroke user draw.  In \cite {gestureexample12}  he firstly compute statistical information about the user stroke then pass it to a Gaussian classifier that had been trained using 10-20 samples. The output of the classifier is classification of the stroke from one of the known classes.

Bayesian classifiers was used in \cite{Vibratory8} as a stroke classifier to recognize different shapes. The recognition is done using feature based statistical Gaussian distribution and Bayesian classifier techniques. The trainer use nine features extracted from segmented symbols (ex number of line segments, number of L intersections, ) all feature has a tolerance within. After all nine feature are computed a Gaussian statically model is constructed.
 
Some systems employ more than one statistical classifier to get better results for the recognition. For example \cite{zernike61} uses Neural network, SVM (support vector machine )and MMD. \cite{polygonfeedback31}
%the closed shaper recognizer which is done using classifiers (SVM , Rule based and ANN ) to make a 
%classification of triangle, rectangle or ellipse

\subsection{Apperance Based Recognition}
\label{sec:ApperanceBasedRecognition}
Template matching is the most used method to recognize strokes and symbols into classes.  Image based template stored on the database is matched with the one user draw to find the correct classification of the strokes drawn.  In most cases, the stroke template is stored as image bitmap \textit{Fig \ref{fig:template}}in the database when the user draws the symbol it is matched using classifiers. \cite {imagetrainable48,HierarchicalParsing7}  used four kind of classifiers to detect the matching template. He used two classifiers to measure similarity and two classifiers to measure dissimilarity then combine them to find best match of drawn stroke from the database.

\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/template.eps}
	\caption[Template matching]{Examples of image templates used to match symbols in \cite{imagetrainable48}. }
	\label{fig:template}
\end{figure}

To refine the matching procedure and create more robust classification \cite {imagetrainable48}  first transform the strokes into polar coordinate then match the transformed stroke with the templates in the database. They claim that enhance the classification procedure as the polar coordinate system due to its definition make the stroke more robust to transformation and rotation.

\cite{templatefrag21}  Introduce new way to match stroke temples. He store template as a sequence of lines and ellipse.  When the user draws a stroke the system, segment it into a sequence of lines and ellipse. The system then matches the stored sequences with computed one to find correct classification.

The main problem of template matching is that in most system the templates are hard coded inside the system and cannot be modified at runtime.




\paragraph{Graph language and visual language describing }
\label{sec:Graph language and visual language describing }


Researchers tried to generate a visual language that can describe hand drawn sketches. In such systems, sketch recognition will be a question of parsing the sketch document into recognizer that parse strokes according to the constructed grammar. 

Researchers proposed more than one visual grammar to use it in sketch recognition. \cite{statisticalparsing26} proposed a language parser that will parse sketched strokes using grammars rules that was constructed . The system first construct a parser that will parse drawn strokes into tokens then formulate those tokens using the grammar rules stored. Parsing is done in two steps; Firstly, the system should accept input of strokes then it use a statistical parser to generate the parse tree. The statically parser make use of the stored rules and probability of drawn stroked and uses Bayesian classifiers to produce the parse tree. 

%\citep*{XPGParser59} i need author   
Introduced a grammar they called an extended positional grammar (XPG) that is based on XpLR parsing methodology \cite{XPGParser59} . The XPG imagine the symbol with a set of attribute as a sentence that can be parsed using the physical, syntactic and semantic information in sketch. They divided the grammar into two kind the first is named ink grammar, it define the symbol of the language as a composition of primitive geometric shapes. The second is language grammar that they use to identify the sketch as a composition of shapes defined by the ink grammar relation. The parsing itself is done using a incrementally bidirectional parsers. They also add a sketch editor to the system to help user to add new symbols and generate its XPG grammar for it \textit{(see Fig[\ref{fig:symboleditor}])}.


\begin{figure}
	\centering
		\includegraphics[scale=0.7]{../../neededfiles/Figures/symboleditor.eps}
	\caption[symbol editor]{The Figure shows the symbol editor that\cite{XPGParser59} uses to generate grammar rules.}
	\label{fig:symboleditor}
\end{figure}

Relational grammar was also used to help in reducing the ambiguity with the help of fuzzy logic\cite {visualpattern43} . The fuzzy set is used to resolve the visual relations of the sketched stroke with others strokes. Spatial relations like (left of, right of) are computed and then passed to the fuzzy sets. The fuzzy set associate a degree of certainty to the shape defined. 
%EfficientAbstract39 also used the grammar language ladder
\cite{Ladder30,GenericHMM28}  Used visual description language which will generate the information of the structure and constrain of each object classified. The system automatically generates java code for the recognizer for each object. The generated code cycles through the strokes drawn to check if any of the recognizers generated had interpreted any symbols partially or completely. HMM network is used to partially segment the strokes drawn to help the recognition process. 

Similar system was constructed in \cite {Ladder30} , where language grammar is written to descript complex shapes ( see \textit{Fig\ref{fig:arrowladderdef1}}) form primitive geometrical, constrains and triggers. The grammar is then passed to "jess" a java rule bases system that produce java code used in recognition of  drawn strokes.

\begin{figure}
	\centering
	\begin {center}
		\subfigure{An Arrow}
			\centering

			{\label {fig:arrow1}\includegraphics[scale=0.75]{../../neededfiles/Figures/arrowladderdef1.eps}}
		\subfigure[Arrow grammar definition]{\includegraphics[scale=0.88]{../../neededfiles/Figures/arrowladderdef2.eps}}
		\end {center}
	\caption[Arrow definition]{The figures show and regular arrow with 2 shafts and head and its definition in Ladder language \cite{Ladder30}}
	\label{fig:arrowladderdef1}
\end{figure}






\subsection{Other hybrid methods}
\label{sec:Otherhybridmethods}

Due to the complexity of the sketch recognition problem, more than one system proposed a hybrid method to solve those problems. They combine more than one approach to recognize symbols the user draws.
\cite{sketchunderstanding1,Simusketch51}  used four kind of classification image, graph matching, statistical and structure based classifiers. Each symbol will contain all graph, statistical, structure information and a (Wight, recognizer) tuples to determine which recognizer has the most influence in recognizing this symbol see \textit{Fig\ref{fig:structuralscemanticdeff}}.
\begin{figure}
	\centering
		\includegraphics[scale=0.5]{../../neededfiles/Figures/structuralscemanticdeff.eps}
	\caption[Structure definitions]{Example of the structure definition of sin symbol in \cite{sketchunderstanding1}.}
	\label{fig:structuralscemanticdeff}
\end{figure}

\cite {HMM53}  firstly normalize the stroke and compute all the statistical features from it. After that, a noise reduction algorithm is used on the strokes which will be translated to produce size and rotation invariance data. Those data is passed to a multistage hybrid recognizer. The first step of his multistage classifier is dynamic programming procedure to compute the optimal degree of similarity and differentiation of symbols. Secondly, a statistical feature ranking is employed on the data produced. Finally, the system will reject all unlikely classification and produce best fit for this stroke using a dynamic programming using domain and context knowledge as input.

\cite{statisticalparsing26} is a statically parser make use of the stored rules and probability of drawn stroked and uses Bayesian classifiers to do the classifications.






%\subsubsection{Fuzzy classifiers }
%\label{sec:FuzzyClassifiers}
%Fuzzy classifiers is used to help in identifying degree of certainty given to certain interpolation the 




%\subsection{Hybrid Systems}
%\label{sec:Hybrid Systems}

Given that the sketch recognition of hand drawn strokes is exceptionally challenging problem the researcher tried to take advantage of additional of combining approaches to achieve higher recognition rate.

Most of the problems of the sketch recognition are not still addressed. To do so, The sketch recognition system must maintain reliably interactive and extensible interface.  The users minor change can cause the recognizers to fail. The user sloppy drawing with over or/and under shoot strokes  \textit{Fig\ref{fig:overstroked}}. Over processing of data and interaction with background are still major problems in the sketched documents.  

To solve some of these problems,\cite{threeproblmes23}  revealed a two stages recognizer that will firstly construct a data graph in which strokes will be added. After constructing the full data graph the recognizer compute all possible solutions and reject any inconsistent alternatives. Second stage, Employs a topology structure based on the geometrical matching using a CSP making use of sub graphs.  

As mentioned before,\cite{visualpattern43,Cali63} combine fuzzy logic sets with language grammar to create more robust classifiers. Grammar rules are used to describe the spatial relationships of the strokes. Fuzzy sets are used to handle the uncertainties of the relation and classification. Therefore, by combining Fuzzy set and spatial grammar rules the system was able quantify the spatial and statistical attribute calculated before in \ref{sec:Statisticalmethods} from the drawn symbols. 

Also the use of HMM with generated visual grammar was introduced in the system by \cite{HMM53} where they use HMM as a stroke segmentor and pass the output to the visual parser. furthermore, \cite{SmartSketch56} used more than one recognizers to recognize closed shapes rule based approach with hypothesis and test strategy, Neural network and SVM.

\paragraph{Dynamic programming}
\label{sec:DynamicProgramming}
 was used by \cite {Mathpad46,templatefrag21}  to calculate the optimal degree of different and similarity of symbols. The system also uses a dynamic programming procedure to find a best fit from the given set of classifications.
 \chapter{Particle Swram Optimization}
\label{sec:ParticleSwramOptimization}

 
\section{Particle Swram Optimization Review}
\label{sec:ParticleSwramOptimizationReview}

%review on the pso alogrithm alone.................


\section{Discrete Particle Swarm Algorithm}
\label{sec:ParticleSwarmAlgorithm}
%\section{Particle Swarm Algorithm}
%\label{PSO}
%What is particle swarm algorithm and how it was used in related researches. 
The main idea of \textit{Particle Swarm Algorithm (PSO)} is to represent each agent with a particle from the solution space \cite{PSOFirst}. Each agent moves the particle with a direction and velocity $v_{ij}$ based on equations \ref{eq:Swarm} \& \ref{eq:Swarm1}.
\begin{equation}
%\[
p_{ij}=p_{ij}+v_{ij},
%\
\label{eq:Swarm1}
\end{equation}
where $p_{ij}$ represent the $jth$ particle in the $ith$ agent and $v_{ij}$ is the velocity of the $jth$ particle in the $ith$ agent.
 %Equation [\ref{eq:Swarm}] shows how velocity and direction of each particle are computed
 \begin{equation}
v_{ij}  = v_{ij}  + c_1 r_1 (lbest_{ij}  - p_{ij} ) + c_2 r_2 (gbest_{ij}  - p_{ij} )
\label{eq:Swarm}
\end{equation}
 where $lbest_{ij}$ is the local best particle, $gbest_{ij}$ is the global best particle, $r_1$ \& $r_2$ are random variables and $c_1$ \& $c_2$ are the swarm system variables.
 After each iteration the global best $g_{best}$ particle and the agent local best $l_{best}$ particle are evaluated based on the maximum fitness functions of all particles in the solution space. The solution is found after achieving a specific number of iteration or after an error threshold is achieved.
Equation \ref{eq:descrite} is used to change the general swarm algorithm into binary particle (\textit{Discrete Particle Swarm Algorithm DPSO}) which handles particle values of either $0$ or $1$ \cite{PSODisceret}. 
 \begin{equation}
   P(i)\Leftarrow 
\{
\begin{array}{c} 
1 \quad \quad if\quad r_{3}>p_{i}  \\

0 \quad \quad if\quad r_{3}<p_{i} 
\label{eq:descrite}
\end{array}\}
\end{equation}
 where $p_{ij}$ is the numerical values of the particle and $r_{3}$ is a random variable.
  